from TwitterAPI import TwitterAPIfrom nltk.corpus import stopwordsimport nltkfrom nltk.stem import SnowballStemmerapi = TwitterAPI("DHdNtd8AhSwFVUNzNlIjrBMhR", "BxrlVSYPgWupByfHYKbOYfYMB9S7RFHjGCdt9pUMYf9QHacyAZ", "21111859-3pdjIGgiZsSND7bL44zKf8zXlXNEQ9EPq2WMbOSGY", "DENxaynyGA9H0Ar0qiWt251ycPExssL1MuRnuFcH7p11V")def removeStopWords(text):    text = text.lower()    text = ' '.join([word for word in text.split() if word not in (stopwords.words('english'))])    return textdef moreCleaning(text):    ret = ''    pastChar = 'A'    for char in text:        if (char>='a' and char<='z') or (char == ' ' and pastChar != ' '):            ret += char            pastChar == char    return ret    def stemWords(text):    print(text)    steamer = SnowballStemmer('english')    words = text.split()    ret = ''    for w in words:        ret += steamer.stem(w) + ' '    return ret[0:-1]def cleanSent(text):    text = removeStopWords(text)    text = moreCleaning(text)    return textdef searchtweetsbykeyword(keyword):        r = api.request('search/tweets', {'q':keyword,'lang': 'en'})	#r = api.request('statuses/user_timeline', {'screen_name':keyword,'count': 20})	#r = api.request('search/tweets', {'q':keyword,'lang': 'en'})	results = []	for item in r.get_iterator():		results.append(item.get("text"))		#results.append(item.get("created_at"))	return resultsdef searchbylocation(keyword):	r = api.request('statuses/filter', {'locations':keyword})	results = []	for item in r.get_iterator():		results.append(item.get("text"))	return resultsdef searchtweetsbyTweet(tweet):	tweet = cleanSent(tweet)	tweets = searchtweetsbykeyword(tweet)        return tweets	